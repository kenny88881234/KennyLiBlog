<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>筆記 - 機器學習 邏輯回歸 | Kenny's Blog</title><meta name="description" content="筆記 - 機器學習 邏輯回歸"><meta name="keywords" content="筆記,機器學習,邏輯回歸"><meta name="author" content="Kenny Li"><meta name="copyright" content="Kenny Li"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="https://kennyliblog.nctu.me/2019/07/19/Machine-learning-logistic-regression/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="筆記 - 機器學習 邏輯回歸"><meta name="twitter:description" content="筆記 - 機器學習 邏輯回歸"><meta name="twitter:image" content="/img/note.jpg"><meta property="og:type" content="article"><meta property="og:title" content="筆記 - 機器學習 邏輯回歸"><meta property="og:url" content="https://kennyliblog.nctu.me/2019/07/19/Machine-learning-logistic-regression/"><meta property="og:site_name" content="Kenny's Blog"><meta property="og:description" content="筆記 - 機器學習 邏輯回歸"><meta property="og:image" content="/img/note.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="Golang-basic" href="https://kennyliblog.nctu.me/2019/07/22/Golang-basic/"><link rel="next" title="問題 - C# 如何使用全域變數" href="https://kennyliblog.nctu.me/2019/07/12/Csharp-use-global-variable/"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":1,"translateDelay":0,"cookieDomain":"https://KennyLi.me/","msgToTraditionalChinese":"简","msgToSimplifiedChinese":"繁"},
  highlight_copy: 'true',
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Bookmark',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days'

  
}</script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#筆記-機器學習-邏輯回歸"><span class="toc-number">1.</span> <span class="toc-text">[筆記] 機器學習 邏輯回歸</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#邏輯回歸算法-Logistic-Regression"><span class="toc-number">1.0.1.</span> <span class="toc-text">邏輯回歸算法 ( Logistic Regression )</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#邏輯函數-Logistic-Function"><span class="toc-number">1.0.1.1.</span> <span class="toc-text">邏輯函數 ( Logistic Function )</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#決策邊界-Decision-Boundary"><span class="toc-number">1.0.1.2.</span> <span class="toc-text">決策邊界 ( Decision Boundary )</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代價函數-Cost-Function"><span class="toc-number">1.0.1.3.</span> <span class="toc-text">代價函數 ( Cost Function )</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#梯度下降-Gradient-Descent"><span class="toc-number">1.0.1.4.</span> <span class="toc-text">梯度下降 ( Gradient Descent )</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#高級優化算法"><span class="toc-number">1.0.1.5.</span> <span class="toc-text">高級優化算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#多類別分類-One-vs-all"><span class="toc-number">1.0.1.6.</span> <span class="toc-text">多類別分類 : One-vs-all</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#tags-筆記-機器學習-邏輯回歸"><span class="toc-number">1.0.1.6.0.1.</span> <span class="toc-text">tags: 筆記 機器學習 邏輯回歸</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/note.jpg)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/">Kenny's Blog</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><span class="pull-right menus"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a><script>document.body.addEventListener('touchstart', function(){ });</script></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title"><div class="posttitle">筆記 - 機器學習 邏輯回歸</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2019-07-19<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> Updated 2019-07-19</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/筆記/">筆記</a></span></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="筆記-機器學習-邏輯回歸"><a href="#筆記-機器學習-邏輯回歸" class="headerlink" title="[筆記] 機器學習 邏輯回歸"></a>[筆記] 機器學習 邏輯回歸</h1><p>用於分類 ( Classification )</p>
<h3 id="邏輯回歸算法-Logistic-Regression"><a href="#邏輯回歸算法-Logistic-Regression" class="headerlink" title="邏輯回歸算法 ( Logistic Regression )"></a>邏輯回歸算法 ( Logistic Regression )</h3><p><code>hθ(x) = g(θᵀx)</code> : 邏輯回歸算式</p>
<h4 id="邏輯函數-Logistic-Function"><a href="#邏輯函數-Logistic-Function" class="headerlink" title="邏輯函數 ( Logistic Function )"></a>邏輯函數 ( Logistic Function )</h4><ul>
<li><p>又稱 S 函數( Sigmoid Function )</p>
</li>
<li><p><img src="https://i.imgur.com/JoFwfc8.png" alt></p>
</li>
<li><p>此函數圖如下 :</p>
</li>
</ul>
<p><img src="https://i.imgur.com/5nhFFfr.png" alt></p>
<ul>
<li><p>此函數可以將任何實數映射到 (0, 1) 區間內</p>
</li>
<li><p>假如 hΘ(x) = 0.7，那預測為 1 的機率是 70%，為 0 的機率是 30%</p>
<ul>
<li><code>hθ(x) = P(y=1 | x;θ) = 1 − P(y=0 | x;θ)</code></li>
<li><code>P(y=0 | x;θ) + P(y=1 | x;θ) = 1</code></li>
</ul>
</li>
</ul>
<h4 id="決策邊界-Decision-Boundary"><a href="#決策邊界-Decision-Boundary" class="headerlink" title="決策邊界 ( Decision Boundary )"></a>決策邊界 ( Decision Boundary )</h4><ul>
<li><p>為了得到 0 與 1，按此轉換 :</p>
<p>  <code>hθ(x) ≥ 0.5 → y = 1</code><br>  <code>hθ(x) &lt; 0.5 → y = 0</code></p>
</li>
<li><p>套入邏輯函數 g 中 :</p>
<p>  <code>g(z) ≥ 0.5 when z ≥ 0</code></p>
</li>
<li><p>再套入邏輯回歸算式 :</p>
<p>  <code>hθ(x) = g(θᵀx) ≥ 0.5 when z = θᵀx ≥0</code></p>
</li>
<li><p>結論 :</p>
<p>  <code>θᵀx ≥ 0 → y = 1</code><br>  <code>θᵀx &lt; 0 → y = 0</code></p>
</li>
<li><p>此時 <code>θᵀx = 0</code> 為決策邊界</p>
<p>  假設 <code>θ = [5 -1 0]</code><br>  ⇒ <code>5 + (-1)x₁ + 0x₂ ≥ 0 → y = 1</code><br>  ⇒ <code>x₁ ≤ 5 → y = 1</code><br>  ⇒ <code>x₁ = 5</code> 為決策邊界</p>
</li>
</ul>
<h4 id="代價函數-Cost-Function"><a href="#代價函數-Cost-Function" class="headerlink" title="代價函數 ( Cost Function )"></a>代價函數 ( Cost Function )</h4><p>不能使用與線性回歸相同的代價函數，因為邏輯函數會導致代價函數，產生多個局部最小值，使它不會是個凸函數 ( convex function )</p>
<p><img src="https://i.imgur.com/16FsaIJ.png" alt></p>
<p>⇒ <code>Cost(hθ(x), y) = -ylog(hθ(x)) - (1 - y)log(1 - hθ(x))</code><br>⇒ <img src="https://i.imgur.com/Yq4Ec4L.png" alt></p>
<p><code>Cost(hθ(x), y) = 0 if hθ(x) = y</code><br><code>Cost(hθ(x), y) → ∞ if y = 0 and hθ(x) → 1</code><br><code>Cost(hθ(x), y) → ∞ if y = 1 and hθ(x) → 0</code></p>
<ul>
<li>假如我們的假設函數 <code>hθ(x)</code> 與正確答案 <code>y</code> 相同，則代價函數為 0 ，相反則會趨於無限大</li>
</ul>
<h4 id="梯度下降-Gradient-Descent"><a href="#梯度下降-Gradient-Descent" class="headerlink" title="梯度下降 ( Gradient Descent )"></a>梯度下降 ( Gradient Descent )</h4><p><img src="https://i.imgur.com/05LyUzd.png" alt></p>
<ul>
<li>與線性回歸的算法相同，一樣需要同步更新 <code>θ</code> 的所有值</li>
</ul>
<h4 id="高級優化算法"><a href="#高級優化算法" class="headerlink" title="高級優化算法"></a>高級優化算法</h4><ul>
<li><p>Conjugate gradient</p>
</li>
<li><p>BFGS</p>
</li>
<li><p>L-BFGS</p>
</li>
<li><p>以上三個的優缺點 :</p>
<ul>
<li><p>優點 :</p>
<ul>
<li>不需要 learning rate α</li>
<li>比梯度下降還快</li>
</ul>
</li>
<li><p>缺點 :</p>
<ul>
<li>較為複雜</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">function [jVal, gradient] = costFunction(theta)</span><br><span class="line">  jVal = [...code to compute J(theta)...];</span><br><span class="line">  gradient = [...code to compute derivative of J(theta)...];</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<ul>
<li>代價函數的函式程式碼</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, 100);</span><br><span class="line">initialTheta = zeros(2,1);</span><br><span class="line">   [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>使用 <code>optimset()</code> 與 <code>fminunc()</code> 來使用優化算法</p>
<ul>
<li>使用 <code>optimset()</code> 設定 <code>GradObj</code> 為 <code>on</code>，將設置梯度打開，設定 <code>MaxIter</code> 為 <code>100</code>，設定100次迭代</li>
<li>給予 <code>fminunc()</code> 代價函數、θ 的初始向量、剛剛設定的 options</li>
</ul>
</li>
</ul>
<h4 id="多類別分類-One-vs-all"><a href="#多類別分類-One-vs-all" class="headerlink" title="多類別分類 : One-vs-all"></a>多類別分類 : One-vs-all</h4><p><code>y ∈ {0,1...n}</code> : 有 n + 1 種類別</p>
<p><code>hθ⁽¹⁾(x) = P(y = 0 | x;θ)</code><br><code>hθ⁽²⁾(x) = P(y = 0 | x;θ)</code><br>. . .<br><code>hθ⁽ⁿ⁾(x) = P(y = 0 | x;θ)</code></p>
<ul>
<li>需要使用到 n + 1 個邏輯回歸分類器 ( Logistic Regression Classifier )</li>
<li>每個分類器為分類<strong>其中一個類別</strong>與<strong>其他類別</strong>，例如 : 0 類別與不是 0 的類別、1 類別與不是 1 的類別…等等</li>
</ul>
<p><img src="https://i.imgur.com/bevfnR3.png" alt></p>
<ul>
<li>預測新數值時，將新數值帶入每個分類器，取輸出值最大的分類器，也就是最大機率是此分類</li>
</ul>
<h6 id="tags-筆記-機器學習-邏輯回歸"><a href="#tags-筆記-機器學習-邏輯回歸" class="headerlink" title="tags: 筆記 機器學習 邏輯回歸"></a>tags: <code>筆記</code> <code>機器學習</code> <code>邏輯回歸</code></h6></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Kenny Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://kennyliblog.nctu.me/2019/07/19/Machine-learning-logistic-regression/">https://kennyliblog.nctu.me/2019/07/19/Machine-learning-logistic-regression/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/筆記/">筆記    </a><a class="post-meta__tags" href="/tags/機器學習/">機器學習    </a><a class="post-meta__tags" href="/tags/邏輯回歸/">邏輯回歸    </a></div><div class="post_share"><div class="social-share" data-image="/img/note.jpg" data-sites="facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/2019/07/22/Golang-basic/"><img class="prev_cover lozad" data-src="/img/note.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>Golang-basic</span></div></a></div><div class="next-post pull-right"><a href="/2019/07/12/Csharp-use-global-variable/"><img class="next_cover lozad" data-src="/img/problem.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>問題 - C# 如何使用全域變數</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/07/12/Octave-basic/" title="筆記 - Octave 基礎"><img class="relatedPosts_cover lozad" data-src="/img/note.jpg"><div class="relatedPosts_title">筆記 - Octave 基礎</div></a></div><div class="relatedPosts_item"><a href="/2019/07/12/Machine-learning-basic-linear-regression/" title="筆記 - 機器學習 基礎與線性回歸"><img class="relatedPosts_cover lozad" data-src="/img/note.jpg"><div class="relatedPosts_title">筆記 - 機器學習 基礎與線性回歸</div></a></div><div class="relatedPosts_item"><a href="/2019/06/17/CSS-basic/" title="筆記 - CSS 基礎"><img class="relatedPosts_cover lozad" data-src="/img/note.jpg"><div class="relatedPosts_title">筆記 - CSS 基礎</div></a></div><div class="relatedPosts_item"><a href="/2019/06/17/Javascript-basic/" title="筆記 - Javascript 基礎"><img class="relatedPosts_cover lozad" data-src="/img/note.jpg"><div class="relatedPosts_title">筆記 - Javascript 基礎</div></a></div><div class="relatedPosts_item"><a href="/2019/06/23/Python-basic/" title="筆記 - Python 基礎"><img class="relatedPosts_cover lozad" data-src="/img/note.jpg"><div class="relatedPosts_title">筆記 - Python 基礎</div></a></div><div class="relatedPosts_item"><a href="/2019/07/22/Golang-basic/" title="Golang-basic"><img class="relatedPosts_cover lozad" data-src="/img/note.jpg"><div class="relatedPosts_title">Golang-basic</div></a></div></div><div class="clear_both"></div></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2019 By Kenny Li</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><i class="fa fa-book" id="readmode" title="Read Mode"> </i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion">繁</a><i class="fa fa-moon-o nightshift" id="nightshift" title="Dark Mode"></i></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/baidupush.js"></script><script src="/js/nightshift.js"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/js/piao.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script></body></html>